# Тестовое задание Mindbox на позицию SRE

## Задача

Не ожидаем production-ready решения. Сделайте, как кажется правильным, опишите процесс поиска и принятые решения.

Опишите решение для веб-приложения в `kubernetes` в виде yaml-манифеста. Оставляйте в коде комментарии по принятым решениям. 
Есть следующие вводные:

- у нас мультизональный кластер (три зоны), в котором пять нод
- приложение требует около 5-10 секунд для инициализации
- по результатам нагрузочного теста известно, что 4 пода справляются с пиковой нагрузкой
- на первые запросы приложению требуется значительно больше ресурсов CPU, в дальнейшем потребление ровное в районе 0.1 CPU. 
По памяти всегда “ровно” в районе 128M memory
- приложение имеет дневной цикл по нагрузке – ночью запросов на порядки меньше, пик – днём
- хотим максимально отказоустойчивый deployment
- хотим минимального потребления ресурсов от этого deployment’а

## Решение

Решение в виде **deployment** и **HPA** (HorizontalPodAutoscaling) для удобства представлено в одном .yml файле.

Начну с того, что поскольку <u>ночью веб-приложение нагружается на порядок меньше, чем днём</u>, то имеет смысл 
дополнительно создать **HPA** (HorizontalPodAutoscaling), т.к. эта сущность - один из способов <u>минимизации потребления ресурсов</u>.
Её главная задача состоит в том, чтобы в зависимости от определённых метрик масштабировать наше веб-приложение.

### Deployment

1. Если известно, что <u>по результатам нагрузочного теста известно, что 4 пода справляются с пиковой нагрузкой</u>, то 
~минимальным~~ наиболее оптимальным количеством реплик для постоянной доступности приложения будет 2, HPA будет масштабировать до 4-х. 
Поэтому я установил `.spec.replicas: 2` (*далее будут ещё аргументы почему именно 2*).

2. Далее я определил `.spec.strategy.type: RollingUpdate` для этого deployment:`maxUnavailable: 1` и 
`maxSurge: 1` обеспечивают гибкое обновление умерших подов и любых изменениях конфигурации всегда будет оставаться
минимум 1 рабочий под (*+ аргумент в пользу 2-х реплик*).

3. Ресурсы, необходимые контейнерам приложения определяются в `...containers[].resources:`. Здесь я определил `requests.cpu: "0.1"` 
и `requests.memory: "128Mi"`, т.к. именно столько приложению требуется по условию для нормальной работы после запуска.
А как раз при запуске и в моменты пиковых нагрузок <u>приложению требуется значительно больше ресурсов CPU</u>, 
поэтому я установил ограничения `limits.cpu: "1"` и `limits.memory: "192Mi"` (с запасом, чтобы держалось при скачках).

4. Чтобы <u>обеспечить отказоустойчивость</u>, необходимо определить пробы: `startupProbe`, `livenessProbe`, `readinessProbe`.
Поскольку <u>приложение требует около 5-10 секунд для инициализации</u>, то важно указать 
`...startupProbe.initialDelaySeconds: 10`, чтобы проба проходила корректно и поды бесконечно не пересоздавались
(*ещё + аргумент в пользу 2-х реплик: даже если какая-то проба не проходит и под перезапускается, то есть запасной*).
Через 5 секунд после того как успешно отработает startup проба, проверять состояние приложения будут liveness и readiness 
пробы (для них `initialDelaySeconds: 5`). Проба на ту проверку, жив ли под будет проходить раз в `...livenessProbe.periodSeconds: 10` сек, 
а проба, определяющая готовность получения подом трафика - раз в `...readinessProbe.periodSeconds: 5` сек. Также, нужно сказать, 
что для всех проб я поставил `timeoutSeconds: 10` (максимальное значение), потому что скорость получения ответа на http запрос на `/healthz` 
сложно предугадать. 

### HPA (HorizontalPodAutoscaling)

1. Наш **deployment** будет масштабироваться от своих 2-х реплик до 4-х (<u>4 пода справляются с пиковой нагрузкой 
по результатам нагрузочного теста</u>).

2. Метрикой я выбрал CPU, а если точнее, то процент использования запрошенных приложением ресурсов, 
описанным в deployment (`...requests.cpu`). Указал `averageUtilization: 60`, чтобы масштабирование в зависимости 
от нагрузки производилось в моменты нарастания средней нагрузки, т.е. потребление > 0.12 CPU => scale up.

3. Наконец, поставил `...behavior.scaleDown.stabilizationWindowSeconds: 300` для того, чтобы после того как пройдёт "час пик", 
**HPA** подождал ещё 10 минут прежде чем повторно уменьшать кол-во реплик (для избегания чрезмерного масштабирования вниз при временном снижении нагрузки).
